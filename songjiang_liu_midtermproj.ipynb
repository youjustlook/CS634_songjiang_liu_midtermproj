{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b7d67a65142c6c",
   "metadata": {},
   "source": [
    "# FA24-CS634101 Data Mining\n",
    "## Midterm Project Report\n",
    "Professor: Yasser Abduallah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97b3779a461753",
   "metadata": {},
   "source": [
    "Student: Songjiang Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e813b2-c6e0-4026-a472-102da0e06753",
   "metadata": {},
   "source": [
    "UCID: sl947"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b74205-150a-4a77-9f9b-1f9a0665ed32",
   "metadata": {},
   "source": [
    "GitHub Repository: https://github.com/youjustlook/CS634_songjiang_liu_midtermproj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa989d-7d80-445b-891f-cb2cf931d105",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This report shows the step by step implementation of algorithms used for generating request items sets and association rules for transactions from 5 databases. The databases are modified from given sample records or generated by ChatGPT as demonstrative data. These algorithms are useful for generating shopping recommendations, finding concurrent patterns, etc. for many industry applications.\n",
    "\n",
    "#### About Support and Confidence\n",
    "Support is the proportion of transactions in a dataset that contain a particular itemset, calculated as as the ratio of the number of transactions containing the itemset to the total number of transactions:\n",
    "**Support**:\n",
    "\\\\[\n",
    "\\text{Support}(A) = \\frac{\\text{Transactions containing } A}{\\text{Total transactions}}\n",
    "\\\\]\n",
    "Confidence is Confidence is the likelihood that an item appears in a transaction given that another item or itemset is already present, calculated as the ratio of the number of transactions containing both the antecedent and the consequent to the number of transactions containing only the antecedent:\n",
    "**Confidence**:\n",
    "\\\\[\n",
    "\\text{Confidence}(A \\rightarrow B) = \\frac{\\text{Transactions containing both } A \\text{ and } B}{\\text{Transactions containing } A}\n",
    "\\\\]\n",
    "â€‹\n",
    "#### About Algorithms Implemented/Used\n",
    "##### self-implemented brute force algorithm\n",
    "The first algorithm in this project is a self-implemented brute force algorithm to find frequent item set and generate association rules from transactions at given support and confidence with enumeration for all possible combinations from item set of 1 to k items in the set. \n",
    "##### built-in Apriori algorithm\n",
    "The second algorithm is the built-in Apriori algorithm in apriori_python package. It does the same thing as the self-implemented brute force algorithm but is optimized for efficiency too.\n",
    "##### built-in FP-Growth algorithm\n",
    "The third algorithm is the built-in FP-Growth algorithm in mlxtend package. It first constructs an FP-tree to  represent the transaction database, and then recursively mining the tree to extract frequent itemsets by identifying conditional patterns and combining them to generate larger frequent itemsets without the need for multiple database scans. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ec854-7d47-4c06-a16e-15ebe4e00b9f",
   "metadata": {},
   "source": [
    "### Code Implementation\n",
    "It takes selection of the databases, self-determined support level and confidence level, and finds the frequent items sets and association rules under the aforementioned requirement. In the end it present the execution time of three algorithms: student-built brute force algorithm, built-in Apriori algorithm, and built-in FP-Growth algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcdeda6-07b5-42a7-94ca-687228aa739e",
   "metadata": {},
   "source": [
    "Run the following code (delete # in the front first for the codes to be effective) to install necessary package if not found in environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8ccc80-bebb-42c7-a623-35d8ca1b2c26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T02:06:22.417183Z",
     "start_time": "2024-10-14T02:06:22.414267Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install apriori_python\n",
    "# !pip install mlxtend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df80e071-ea55-49ff-ab55-93822a632823",
   "metadata": {},
   "source": [
    "#### Step 1: Import and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c7fefe6-77b3-4a44-aceb-2af626261262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T02:06:26.975263Z",
     "start_time": "2024-10-14T02:06:22.428193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, welcome to the Apriori Algorithm. Version 1.0\n",
      "Please select a database to load:\n",
      "1. Amazon\n",
      "2. BestBuy\n",
      "3. HomeDepot\n",
      "4. K-mart\n",
      "5. Nike\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of your choice:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Nike database successfully.\n",
      "Number of transactions: 20\n",
      "Number of items in the item set: 10\n",
      "Items in the item set:\n",
      "Soccer Shoe\n",
      "Socks\n",
      "Modern Pants\n",
      "Dry Fit V-Nick\n",
      "Tech Pants\n",
      "Hoodies\n",
      "Running Shoe\n",
      "Sweatshirts\n",
      "Rash Guard\n",
      "Swimming Shirt\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from apriori_python.apriori import apriori\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "print(\"Hello, welcome to the Apriori Algorithm. Version 1.0\")\n",
    "\n",
    "def load_database(choice):\n",
    "    databases = {\n",
    "        1: \"Amazon.csv\",\n",
    "        2: \"BestBuy.csv\",\n",
    "        3: \"HomeDepot.csv\",\n",
    "        4: \"K-mart.csv\",\n",
    "        5: \"Nike.csv\"\n",
    "    }\n",
    "    try:\n",
    "        return pd.read_csv(databases[choice])\n",
    "    except KeyError:\n",
    "        print(\"Invalid choice. Please enter a number between 1 and 5.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {databases[choice]} not found.\")\n",
    "        return None\n",
    "\n",
    "def get_item_set(transactions_data):\n",
    "    item_set = set()\n",
    "    for transaction in transactions_data.iloc[:, 1]:\n",
    "        items = transaction.split(', ')\n",
    "        item_set.update(items)\n",
    "    return item_set\n",
    "\n",
    "# Load the database at choice\n",
    "databases = [\"Amazon\", \"BestBuy\", \"HomeDepot\", \"K-mart\", \"Nike\"]\n",
    "\n",
    "while True:\n",
    "    print(\"Please select a database to load:\")\n",
    "    for i, db in enumerate(databases, 1):\n",
    "        print(f\"{i}. {db}\")\n",
    "    \n",
    "    try:\n",
    "        choice = int(input(\"Enter the number of your choice: \"))\n",
    "        if choice < 1 or choice > len(databases):\n",
    "            raise ValueError(\"Invalid input. Please enter a number between 1 and 5.\")\n",
    "        \n",
    "        transactions_data = load_database(choice)\n",
    "        \n",
    "        if transactions_data is None:\n",
    "            continue  # if loading the database fails, ask for input again\n",
    "        \n",
    "        transactions_data_each = transactions_data.iloc[:, 1]\n",
    "        print(f\"Loaded {databases[choice-1]} database successfully.\")\n",
    "\n",
    "        # Display number of transactions\n",
    "        num_transactions = len(transactions_data)\n",
    "        print(f\"Number of transactions: {num_transactions}\")\n",
    "\n",
    "        # Display item set information\n",
    "        item_set = get_item_set(transactions_data)\n",
    "        num_items = len(item_set)\n",
    "        print(f\"Number of items in the item set: {num_items}\")\n",
    "        print(\"Items in the item set:\")\n",
    "        for item in item_set:\n",
    "            print(item)\n",
    "        \n",
    "        break  # exit the loop if everything is successful\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c52ac-5dc2-474e-a1e9-db82ae9765fb",
   "metadata": {},
   "source": [
    "#### Step 2: User Input for Support and Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a13e9b-a492-4d60-8c34-e764b7356264",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T02:06:32.240721Z",
     "start_time": "2024-10-14T02:06:26.993710Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the minimum support level in % (larger than 0 and lower than 100%):  50\n",
      "Enter the minimum confidence level in % (larger than 0 and lower than 100%):  40\n"
     ]
    }
   ],
   "source": [
    "# Get user input for minimum support and minimum confidence\n",
    "while True:\n",
    "    try:\n",
    "        min_support = float(input(\"Enter the minimum support level in % (larger than 0 and lower than 100%): \"))\n",
    "        if 0 < min_support < 100:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter a value between 0 and 100.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a numeric value.\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        min_confidence = float(input(\"Enter the minimum confidence level in % (larger than 0 and lower than 100%): \"))\n",
    "        if 0 < min_confidence < 100:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter a value between 0 and 100.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a numeric value.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb15b5-9f62-4309-b5d2-9e8dd5916dae",
   "metadata": {},
   "source": [
    "#### Step 3: Brute Force Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63b6cd9-bc7b-492a-84ab-3a145580d0f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T02:06:32.270448Z",
     "start_time": "2024-10-14T02:06:32.257325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Frequent item sets using brute force method: item | support\n",
      "{'Socks'} | 0.65\n",
      "{'Modern Pants'} | 0.5\n",
      "{'Dry Fit V-Nick'} | 0.5\n",
      "{'Running Shoe'} | 0.7\n",
      "{'Sweatshirts'} | 0.65\n",
      "{'Rash Guard'} | 0.6\n",
      "{'Swimming Shirt'} | 0.55\n",
      "{'Rash Guard', 'Dry Fit V-Nick'} | 0.5\n",
      "{'Running Shoe', 'Socks'} | 0.55\n",
      "{'Sweatshirts', 'Socks'} | 0.6\n",
      "{'Modern Pants', 'Sweatshirts'} | 0.5\n",
      "{'Running Shoe', 'Sweatshirts'} | 0.55\n",
      "{'Rash Guard', 'Swimming Shirt'} | 0.5\n",
      "{'Running Shoe', 'Sweatshirts', 'Socks'} | 0.5\n",
      "--------------------\n",
      "Association rules using brute force method:\n",
      "Rule 1: {'Rash Guard'} -> {'Dry Fit V-Nick'} (support: 0.5, confidence: 0.8333333333333334)\n",
      "Rule 2: {'Dry Fit V-Nick'} -> {'Rash Guard'} (support: 0.5, confidence: 1.0)\n",
      "Rule 3: {'Running Shoe'} -> {'Socks'} (support: 0.55, confidence: 0.7857142857142858)\n",
      "Rule 4: {'Socks'} -> {'Running Shoe'} (support: 0.55, confidence: 0.8461538461538461)\n",
      "Rule 5: {'Sweatshirts'} -> {'Socks'} (support: 0.6, confidence: 0.923076923076923)\n",
      "Rule 6: {'Socks'} -> {'Sweatshirts'} (support: 0.6, confidence: 0.923076923076923)\n",
      "Rule 7: {'Modern Pants'} -> {'Sweatshirts'} (support: 0.5, confidence: 1.0)\n",
      "Rule 8: {'Sweatshirts'} -> {'Modern Pants'} (support: 0.5, confidence: 0.7692307692307692)\n",
      "Rule 9: {'Running Shoe'} -> {'Sweatshirts'} (support: 0.55, confidence: 0.7857142857142858)\n",
      "Rule 10: {'Sweatshirts'} -> {'Running Shoe'} (support: 0.55, confidence: 0.8461538461538461)\n",
      "Rule 11: {'Rash Guard'} -> {'Swimming Shirt'} (support: 0.5, confidence: 0.8333333333333334)\n",
      "Rule 12: {'Swimming Shirt'} -> {'Rash Guard'} (support: 0.5, confidence: 0.9090909090909091)\n",
      "Rule 13: {'Running Shoe'} -> {'Sweatshirts', 'Socks'} (support: 0.5, confidence: 0.7142857142857143)\n",
      "Rule 14: {'Sweatshirts'} -> {'Running Shoe', 'Socks'} (support: 0.5, confidence: 0.7692307692307692)\n",
      "Rule 15: {'Socks'} -> {'Running Shoe', 'Sweatshirts'} (support: 0.5, confidence: 0.7692307692307692)\n",
      "Rule 16: {'Running Shoe', 'Sweatshirts'} -> {'Socks'} (support: 0.5, confidence: 0.9090909090909091)\n",
      "Rule 17: {'Running Shoe', 'Socks'} -> {'Sweatshirts'} (support: 0.5, confidence: 0.9090909090909091)\n",
      "Rule 18: {'Sweatshirts', 'Socks'} -> {'Running Shoe'} (support: 0.5, confidence: 0.8333333333333334)\n"
     ]
    }
   ],
   "source": [
    "# Brute force method\n",
    "def generate_candidates(item_set, length):\n",
    "    return [set(item) for item in itertools.combinations(item_set, length)]\n",
    "\n",
    "def is_frequent(candidate, transactions, min_support_count):\n",
    "    count = sum(1 for transaction in transactions if candidate.issubset(transaction))\n",
    "    return count >= min_support_count\n",
    "\n",
    "def count_frequent(candidate, transactions):\n",
    "    count = sum(1 for transaction in transactions if candidate.issubset(transaction))\n",
    "    return count\n",
    "\n",
    "def brute_force_apriori(transactions, item_set, min_support):\n",
    "    min_support_count = len(transactions) * min_support\n",
    "    frequent_itemsets = []\n",
    "    k = 1\n",
    "    current_itemsets = [set([item]) for item in item_set]\n",
    "\n",
    "    while current_itemsets:\n",
    "        next_itemsets = []\n",
    "        for itemset in current_itemsets:\n",
    "            if is_frequent(itemset, transactions, min_support_count):\n",
    "                frequent_itemsets.append(itemset)\n",
    "        k += 1\n",
    "        current_itemsets = generate_candidates(set(itertools.chain.from_iterable(frequent_itemsets)), k)\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "def find_association_rules(frequent_collections, data_samples, threshold_confidence):\n",
    "    association_rules = []\n",
    "    for collection in frequent_collections:\n",
    "        for num_elements in range(1, len(collection)):\n",
    "            for precursor in itertools.combinations(collection, num_elements):\n",
    "                precursor = set(precursor)\n",
    "                outcome = collection - precursor\n",
    "                if outcome:\n",
    "                    support = sum(1 for sample in data_samples if collection.issubset(sample)) / len(data_samples)\n",
    "                    confidence = support / (sum(1 for sample in data_samples if precursor.issubset(sample)) / len(data_samples))\n",
    "                    if confidence >= threshold_confidence:\n",
    "                        association_rules.append((precursor, outcome, support, confidence))\n",
    "    return association_rules\n",
    "\n",
    "# Running the brute force method\n",
    "transactions_data_processed = []\n",
    "order = sorted(item_set)\n",
    "for lines in transactions_data_each:\n",
    "    trans = list(lines.strip().split(', '))\n",
    "    trans_l = list(np.unique(trans))\n",
    "    trans_l.sort(key=lambda x: order.index(x))\n",
    "    transactions_data_processed.append(sorted(trans_l))\n",
    "\n",
    "start_time_brute_force_freq_itemset = time.time_ns()\n",
    "frequent_itemsets = brute_force_apriori(transactions_data_processed, item_set, min_support / 100)\n",
    "brute_force_time_freq_itemset = time.time_ns() - start_time_brute_force_freq_itemset\n",
    "\n",
    "print(\"--------------------\\nFrequent item sets using brute force method: item | support\")\n",
    "for itemset in frequent_itemsets:\n",
    "    print(str(itemset) + \" | \" + str(count_frequent(itemset, transactions_data_processed)/len(transactions_data_processed)))\n",
    "\n",
    "\n",
    "print(\"--------------------\\nAssociation rules using brute force method:\")\n",
    "start_time_self_association_rules = time.time_ns()\n",
    "rules = find_association_rules(frequent_itemsets, transactions_data_processed, min_confidence / 100)\n",
    "find_rules_time = time.time_ns() - start_time_self_association_rules\n",
    "for i, rule in enumerate(rules):\n",
    "    antecedent, consequent, support, confidence = rule\n",
    "    print(f\"Rule {i+1}: {antecedent} -> {consequent} (support: {support}, confidence: {confidence})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0257f974-8052-4247-a258-735f6a9e3023",
   "metadata": {},
   "source": [
    "#### Step 4: Built-in Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c76b6efa-1376-47e8-9ad3-45775abd8fb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T02:06:32.293121Z",
     "start_time": "2024-10-14T02:06:32.288089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Check with Built-in Apriori Algorithm:\n",
      "--------------------\n",
      "Frequent item sets with Built-in Apriori algorithm:\n",
      "{1: {frozenset({'Running Shoe'}), frozenset({'Modern Pants'}), frozenset({'Swimming Shirt'}), frozenset({'Dry Fit V-Nick'}), frozenset({'Socks'}), frozenset({'Rash Guard'}), frozenset({'Sweatshirts'})}, 2: {frozenset({'Sweatshirts', 'Socks'}), frozenset({'Running Shoe', 'Socks'}), frozenset({'Running Shoe', 'Sweatshirts'}), frozenset({'Rash Guard', 'Swimming Shirt'}), frozenset({'Rash Guard', 'Dry Fit V-Nick'}), frozenset({'Modern Pants', 'Sweatshirts'})}, 3: {frozenset({'Running Shoe', 'Sweatshirts', 'Socks'})}}\n",
      "--------------------\n",
      "Association rules with Built-in Apriori algorithm:\n",
      "Rule 1: [{'Running Shoe'}, {'Sweatshirts', 'Socks'}, 0.7142857142857143]\n",
      "Rule 2: [{'Sweatshirts'}, {'Modern Pants'}, 0.7692307692307693]\n",
      "Rule 3: [{'Sweatshirts'}, {'Running Shoe', 'Socks'}, 0.7692307692307693]\n",
      "Rule 4: [{'Socks'}, {'Running Shoe', 'Sweatshirts'}, 0.7692307692307693]\n",
      "Rule 5: [{'Running Shoe'}, {'Socks'}, 0.7857142857142857]\n",
      "Rule 6: [{'Running Shoe'}, {'Sweatshirts'}, 0.7857142857142857]\n",
      "Rule 7: [{'Rash Guard'}, {'Swimming Shirt'}, 0.8333333333333334]\n",
      "Rule 8: [{'Rash Guard'}, {'Dry Fit V-Nick'}, 0.8333333333333334]\n",
      "Rule 9: [{'Sweatshirts', 'Socks'}, {'Running Shoe'}, 0.8333333333333334]\n",
      "Rule 10: [{'Socks'}, {'Running Shoe'}, 0.8461538461538461]\n",
      "Rule 11: [{'Sweatshirts'}, {'Running Shoe'}, 0.8461538461538461]\n",
      "Rule 12: [{'Swimming Shirt'}, {'Rash Guard'}, 0.9090909090909091]\n",
      "Rule 13: [{'Running Shoe', 'Sweatshirts'}, {'Socks'}, 0.9090909090909091]\n",
      "Rule 14: [{'Running Shoe', 'Socks'}, {'Sweatshirts'}, 0.9090909090909091]\n",
      "Rule 15: [{'Sweatshirts'}, {'Socks'}, 0.9230769230769231]\n",
      "Rule 16: [{'Socks'}, {'Sweatshirts'}, 0.9230769230769231]\n",
      "Rule 17: [{'Dry Fit V-Nick'}, {'Rash Guard'}, 1.0]\n",
      "Rule 18: [{'Modern Pants'}, {'Sweatshirts'}, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Check with built-in Apriori algorithm\n",
    "print(\"--------------------\\nCheck with Built-in Apriori Algorithm:\")\n",
    "start_apriori_time_freq_itemset_and_rules = time.time_ns()\n",
    "freq_item_set, rules = apriori(transactions_data_processed, min_support/100, min_confidence/100)\n",
    "apriori_time_freq_itemset_and_rules = time.time_ns() - start_apriori_time_freq_itemset_and_rules\n",
    "\n",
    "print(\"--------------------\\nFrequent item sets with Built-in Apriori algorithm:\")\n",
    "print(freq_item_set)\n",
    "\n",
    "print(\"--------------------\\nAssociation rules with Built-in Apriori algorithm:\")\n",
    "for i, rule in enumerate(rules):\n",
    "    print(f\"Rule {i+1}: {rule}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c866ed-4228-426d-ba1a-4f49790249f6",
   "metadata": {},
   "source": [
    "The self-built brute force algorithm generates same frequent item sets andd association rules as the built-in Apriori algotithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6666cb4-6a40-4b4c-95ba-8b207cdb94a5",
   "metadata": {},
   "source": [
    "#### Step 5: FP-Growth Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1f8ac78-74a0-4438-83c4-80b57b8f9d62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T02:06:32.326956Z",
     "start_time": "2024-10-14T02:06:32.312941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Check with Built-in FP-Growth algorithm:\n",
      "    support                            itemsets\n",
      "0      0.70                      (Running Shoe)\n",
      "1      0.65                       (Sweatshirts)\n",
      "2      0.65                             (Socks)\n",
      "3      0.50                      (Modern Pants)\n",
      "4      0.60                        (Rash Guard)\n",
      "5      0.55                    (Swimming Shirt)\n",
      "6      0.50                    (Dry Fit V-Nick)\n",
      "7      0.55         (Running Shoe, Sweatshirts)\n",
      "8      0.60                (Sweatshirts, Socks)\n",
      "9      0.55               (Running Shoe, Socks)\n",
      "10     0.50  (Running Shoe, Sweatshirts, Socks)\n",
      "11     0.50         (Modern Pants, Sweatshirts)\n",
      "12     0.50        (Rash Guard, Swimming Shirt)\n",
      "13     0.50        (Rash Guard, Dry Fit V-Nick)\n",
      "--------------------\n",
      "Association rules with FP-Growth algorithm: rule, support, confidence\n",
      "Rule 1: {'Running Shoe'} -> {'Sweatshirts'} (support: 0.55, confidence: 0.79)\n",
      "Rule 2: {'Sweatshirts'} -> {'Running Shoe'} (support: 0.55, confidence: 0.85)\n",
      "Rule 3: {'Sweatshirts'} -> {'Socks'} (support: 0.60, confidence: 0.92)\n",
      "Rule 4: {'Socks'} -> {'Sweatshirts'} (support: 0.60, confidence: 0.92)\n",
      "Rule 5: {'Running Shoe'} -> {'Socks'} (support: 0.55, confidence: 0.79)\n",
      "Rule 6: {'Socks'} -> {'Running Shoe'} (support: 0.55, confidence: 0.85)\n",
      "Rule 7: {'Running Shoe', 'Sweatshirts'} -> {'Socks'} (support: 0.50, confidence: 0.91)\n",
      "Rule 8: {'Running Shoe', 'Socks'} -> {'Sweatshirts'} (support: 0.50, confidence: 0.91)\n",
      "Rule 9: {'Sweatshirts', 'Socks'} -> {'Running Shoe'} (support: 0.50, confidence: 0.83)\n",
      "Rule 10: {'Running Shoe'} -> {'Sweatshirts', 'Socks'} (support: 0.50, confidence: 0.71)\n",
      "Rule 11: {'Sweatshirts'} -> {'Running Shoe', 'Socks'} (support: 0.50, confidence: 0.77)\n",
      "Rule 12: {'Socks'} -> {'Running Shoe', 'Sweatshirts'} (support: 0.50, confidence: 0.77)\n",
      "Rule 13: {'Modern Pants'} -> {'Sweatshirts'} (support: 0.50, confidence: 1.00)\n",
      "Rule 14: {'Sweatshirts'} -> {'Modern Pants'} (support: 0.50, confidence: 0.77)\n",
      "Rule 15: {'Rash Guard'} -> {'Swimming Shirt'} (support: 0.50, confidence: 0.83)\n",
      "Rule 16: {'Swimming Shirt'} -> {'Rash Guard'} (support: 0.50, confidence: 0.91)\n",
      "Rule 17: {'Rash Guard'} -> {'Dry Fit V-Nick'} (support: 0.50, confidence: 0.83)\n",
      "Rule 18: {'Dry Fit V-Nick'} -> {'Rash Guard'} (support: 0.50, confidence: 1.00)\n"
     ]
    }
   ],
   "source": [
    "# Check with fp-growth algorithm\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions_data_processed).transform(transactions_data_processed)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "start_time_fpgrowth = time.time_ns()\n",
    "freq_item_set_fp = fpgrowth(df_encoded, min_support/100, use_colnames=True)\n",
    "fpgrowth_time = time.time_ns() - start_time_fpgrowth\n",
    "\n",
    "print(\"--------------------\\nCheck with Built-in FP-Growth algorithm:\")\n",
    "print(freq_item_set_fp)\n",
    "\n",
    "start_time_association_rules = time.time_ns()\n",
    "rules_fp = association_rules(freq_item_set_fp, metric=\"confidence\", min_threshold=min_confidence / 100)\n",
    "association_rules_time = time.time_ns() - start_time_association_rules\n",
    "\n",
    "print(\"--------------------\\nAssociation rules with FP-Growth algorithm: rule, support, confidence\")\n",
    "for idx, row in rules_fp.iterrows():\n",
    "    antecedent = set(row['antecedents'])\n",
    "    consequent = set(row['consequents'])\n",
    "    support = row['support']\n",
    "    confidence = row['confidence']\n",
    "    print(f\"Rule {idx + 1}: {antecedent} -> {consequent} (support: {support:.2f}, confidence: {confidence:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b35f92-d87f-4927-9ff8-b475ad69b872",
   "metadata": {},
   "source": [
    "The the results from brute force, apriori, and fp-growth are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d175096a-6dc6-412a-b1a0-64e18143c7cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T02:06:32.409314Z",
     "start_time": "2024-10-14T02:06:32.405999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Times (in nanoseconds):\n",
      "Self-Built Brute Force: 2002600 ns\n",
      "Built-in Apriori: 1003500 ns\n",
      "Built-In FP-Growth: 5005500 ns\n",
      "---------------------\n",
      "Footnote:\n",
      " Built-in Apriori returns frequent item sets and rules in one go, while the other two generate it separately. \n",
      " And the databases only have 20 transactions. \n",
      " Therefore, sometimes Built-in Apriori took the least time, and sometimes FP-Growth is even slower than self-built brute force. \n"
     ]
    }
   ],
   "source": [
    "# Print combined execution times\n",
    "print(\"\\nExecution Times (in nanoseconds):\")\n",
    "print(f\"Self-Built Brute Force: {brute_force_time_freq_itemset + find_rules_time} ns\")\n",
    "print(f\"Built-in Apriori: {apriori_time_freq_itemset_and_rules} ns\")\n",
    "print(f\"Built-In FP-Growth: {fpgrowth_time + association_rules_time} ns\")\n",
    "print(\"---------------------\\nFootnote:\\n Built-in Apriori returns frequent item sets and rules in one go, while the other two generate it separately. \\n And the databases only have 20 transactions. \\n Therefore, sometimes Built-in Apriori took the least time, and sometimes FP-Growth is even slower than self-built brute force. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d717f0be-94f5-4240-9671-70100252cf9e",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This project guides you to understand the use and functioning steps of typical association rule algorithms: one self-built brute force algorithm, which is a de facto Apriori algorithm, one optimized-efficient built-in Apriori algorithm, and one more scale-efficient FP-Growth algorim. The frequent items sets and association rules generated are matched with each other; however, their running time are diffent and can vary depending on scale of dataset and their own methodology behind. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
